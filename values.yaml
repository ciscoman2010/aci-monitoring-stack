image:
  repository: quay.io/camillo/aci-exporter
  tag: 58_newAciConnection_fix
  pullPolicy: Always
config:
  port: 9643
  url: aci-exporter-svc

  # Helm can't use variables in a Value file so naming the service 
  # Dynamically (i.e. including the release name) will break the prometheus sub-chart
  # The easiest solution (and the only one I found that does not involves patching the prom sub-chart)
  # is to use anchors so we can define the http_service_discovery URL needed by prometheus 
  # and then pass it in the prometheus.serverFiles.prometheus.yml.scrape_configs.http_sd_configs.url paramater
  # Sadly acnhors don't support string concatenation so we have to ensure the aci-sd-url matches the config.port and config.url
  # You  need to change this ONLY if you want to deploy this chart multiple times in the same namespace to avoid 
  # having duplicate service name in the same NS.
  aciServiceDiscoveryURL: http://aci-exporter-svc:9643/sd
  prefix: aci_
  httpclient:
    insecurehttps: true
    keepalive: 120
    timeout: 30


prometheus:
  configmapReload:
    prometheus:
      extraConfigmapMounts:
        - name: prometheus-alerts
          mountPath: /etc/alerts.d
          configMap: prometheus-alerts
          readOnly: true
      extraVolumeDirs:
        - /etc/alerts.d
  # We are deploying a dedicated Prometheus instance for the aci-exporter
  # So we don't care about collecting metrics from the K8s cluster itself
  kube-state-metrics:
    enabled: false
  prometheus-node-exporter:
    enabled: false
  prometheus-pushgateway:
    enabled: false
  server:
    configMapOverrideName: prometheus-config
    extraConfigmapMounts:
      - name: prometheus-alerts
        mountPath: /etc/alerts.d
        configMap: prometheus-alerts
        readOnly: true
    prefixURL: ""
    extraArgs:
      # Is a bit of an odd syntax but this is how is ENABLED
      web.enable-remote-write-receiver: null

  service:
    servicePort: 80
  alertmanager:
    enabled: true
    service:
      port: 9093
grafana:
  enabled: true
  defaultDashboardsEnabled: false
  sidecar:
    datasources:
      name: Prometheus
      uid: prometheus
      enabled: true
      defaultDatasourceEnabled: true
      isDefaultDatasource: true
      label: grafana_datasource
      labelValue: "aci-monitoring-stack"
      alertmanager:
        enabled: true
        name: Alertmanager
        uid: alertmanager
        handleGrafanaManagedAlerts: false
        implementation: prometheus
    dashboards:
      enabled: true
      label: grafana_dashboard
      labelValue: "aci-monitoring-stack"
      # This is needed to place the dashboard inside the folder specified
      # in the `k8s-sidecar-target-directory` annotation in the ConfigMap
      provider:
        foldersFromFilesStructure: true
        allowUiUpdates: true
    alerts:
      enabled: false

promtail:
  enabled: true
  daemonset:
    enabled: false
  deployment:
    enabled: true
  replicaCount: 1
  #Only used to ingest external logs from ACI so no need to mount any of the local volumes
  defaultVolumes: []
  defaultVolumeMounts: []
  podSecurityPolicy:
    privileged: fasle
    allowPrivilegeEscalation: false
    volumes:
      - 'secret'
      - 'downwardAPI'
  config:
    clients:
    - url: http://loki-gateway/loki/api/v1/push
    snippets:
      scrapeConfigs: |
        - job_name: syslog
          syslog:
            listen_address: 0.0.0.0:1514
            labels:
              job: aci-monitoring-stack
          relabel_configs:
            - source_labels:
                - __syslog_message_hostname
              target_label: name

loki:
  enabled: true
  fullnameOverride: "loki"
  monitoring:
    dashboards:
      enabled: false
    rules:
      enabled: false
    serviceMonitor:
      enabled: false
    selfMonitoring:
      enabled: false
      grafanaAgent:
        installOperator: false
    lokiCanary:
      enabled: false
  lokiCanary:
    enabled: false
  test:
    enabled: false
  loki:
    enabled: true
    auth_enabled: false
    gateway:
      service:
        port: 80
    datasource:
      jsonData: "{}"
      uid: ""
    commonConfig:
      replication_factor: 1
    schemaConfig:
      configs:
        - from: 2024-04-01
          store: tsdb
          object_store: s3
          schema: v13
          index:
            prefix: loki_index_
            period: 24h
    ingester:
      chunk_encoding: snappy
    tracing:
      enabled: false
    querier:
      # Default is 4, if you have enough memory and CPU you can increase, reduce if OOMing
      max_concurrent: 4
    sidecar:
      rules:
        enabled: true
        label: loki_rule
        labelValue: ""
    rulerConfig:
      wal:
        dir: /rules/ruler-wal
      storage:
        type: local
        local:
          directory: /rules
      rule_path: /rules/fake
      remote_write:
        enabled: true
        clients:
          fake:
            url: http://aci-mon-stack-prometheus-server:80/api/v1/write
      alertmanager_url: http://aci-mon-stack-alertmanager:9093
      ring:
        kvstore:
          store: inmemory
      enable_alertmanager_v2: true

  deploymentMode: SimpleScalable
  backend:
    replicas: 3
  read:
    replicas: 3
  write:
    replicas: 3
  # Enable minio for storage
  minio:
    enabled: true
  singleBinary:
    replicas: 0

  ingester:
    replicas: 0
  querier:
    replicas: 0
  queryFrontend:
    replicas: 0
  queryScheduler:
    replicas: 0
  distributor:
    replicas: 0
  compactor:
    replicas: 0
  indexGateway:
    replicas: 0
  bloomCompactor:
    replicas: 0
  bloomGateway:
    replicas: 0